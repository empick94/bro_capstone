{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been modified to remove sensitive data. It excludes the original dataset, the output of each cell, and some feature engineering based off of domain knowledge. The inputs are still included for the purpose of understanding our machine learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from kmodes.kmodes import KModes\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "limit the dataframe to the size we can handle by pulling in 1 in 20 rows. Dr. Keith says this should still be representative of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = []\n",
    "for i in range(100000000):\n",
    "    if i % 20 != 0:\n",
    "        skip.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "df = pd.read_csv(r\"C:\\Users\\hanbrolo\\Documents\\kerberos_2.25_to_3.4.csv\", skiprows=skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on domain knowledge, we've grouped IPs into different departments or services they represent. We use this engineered feature in our model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The logic for this feature has been removed from the notebook due to its sensitive nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another engineered feature - cagetorical buckets for day of week and time of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ts = pd.to_datetime(df.ts)\n",
    "df['day_of_week'] = df.ts.dt.weekday_name\n",
    "hours = {\n",
    "    0: \"late_night\",\n",
    "    1: \"late_night\",\n",
    "    2: \"early_morning\",\n",
    "    3: \"early_morning\",\n",
    "    4: \"early_morning\",\n",
    "    5: \"early_morning\",\n",
    "    6: \"morning\",\n",
    "    7: \"morning\",\n",
    "    8: \"morning\",\n",
    "    9: \"morning\",\n",
    "    10: \"afternoon\",\n",
    "    11: \"afternoon\",\n",
    "    12: \"afternoon\",\n",
    "    13: \"afternoon\",\n",
    "    14: \"evening\",\n",
    "    15: \"evening\",\n",
    "    16: \"evening\",\n",
    "    17: \"evening\",\n",
    "    18: \"night\",\n",
    "    19: \"night\",\n",
    "    20: \"night\",\n",
    "    21: \"night\",\n",
    "    22: \"late_night\",\n",
    "    23: \"late_night\"\n",
    "}\n",
    "df['time_of_day_bin'] =  [hours[i] for i in df.ts.dt.hour]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['error_msg','request_type', 'service','day_of_week','time_of_day_bin','orig_ip_group','resp_ip_group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling missing values as their own category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['success'] = [\"yes\" if i else \"no\" for i in df[\"success\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['error_msg'] = df['error_msg'].fillna(\"SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols] = df[cols].fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with 10 clusters. Thus number provided enough distinct examples of \"normal\" behavior could be like that our anomalies were meaningful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KModes(n_clusters=15, init='Huang', n_init=4, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = km.fit_predict(df[cols])\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These centroids represent the most common values for each of the chosen features. We'll identify the records that are the most dissimilar to these centroids in order to find anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.cluster_centroids_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centroids = pd.DataFrame(km.cluster_centroids_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centroids.to_pickle(\"kerb_kmodes_centroids_15_clusters_ip_group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the distance between a row and the closest centroid. For records of categorical data, distance is simply increased by one for each column in the row that doesn't match the value of the corresponding column in the assigned centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissim_distance(a,b):\n",
    "    distance = 0\n",
    "    for ai, bi in zip(a,b):\n",
    "        if ai != bi:\n",
    "            distance += 1\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_dist(row):\n",
    "    cluster_index = row['cluster']\n",
    "    return dissim_distance(row[cols],km.cluster_centroids_[cluster_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_dist'] = df.apply(lambda row: get_min_dist(row),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find anomalies. These are defined as the rows that have the largest distance from their assigned closest cluster. We found with this dataset a distance of 5 or greater was pretty anomalous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalies = df[df.min_dist >= 5]#[cols + ['id.orig_h','id.resp_h','']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalies.to_pickle(\"kmodes_kerb_9_cols_15_clusters_anomalies_max_distances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalies.to_csv(path_or_buf=\"kerb_anomalies_15_clusters_ip_group.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the anomalies! We looked through these by hand to determine if any of them were of concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------The Remainder of this notebook represent other work that I tried, but didn't end up using. It may be useful for showing the process, but this is the end of the code that helped determine the anomalies--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you need to calculate distance between ALL items and ALL clusters, use this. But it's very slow.\n",
    "K_NUM_CLUSTERS = 15\n",
    "\n",
    "for i in range(K_NUM_CLUSTERS):\n",
    "    df['dist_from_' + str(i)] = df[cols].apply(lambda row: dissim_distance(row,km.cluster_centroids_[i]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Don't use this, the way above is faster and does the same thing\n",
    "dist_cols = []\n",
    "\n",
    "K_NUM_CLUSTERS = 15\n",
    "\n",
    "for i in range(K_NUM_CLUSTERS):\n",
    "    dist_cols.append([])\n",
    "\n",
    "for row in df[cols].iterrows():\n",
    "    col_count = 0\n",
    "    for c in km.cluster_centroids_:\n",
    "        dist_cols[col_count].append(dissim_distance(row[1], c))\n",
    "        col_count += 1\n",
    "        \n",
    "col_count = 0    \n",
    "for col in dist_cols:\n",
    "    df['dist_from_' + str(col_count)] = col\n",
    "    col_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"kmodes_kerb_9_features_15_clusters_distances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_cols =  ['dist_from_0','dist_from_1','dist_from_2','dist_from_3','dist_from_4','dist_from_5','dist_from_6','dist_from_7','dist_from_8','dist_from_9','dist_from_10','dist_from_11','dist_from_12','dist_from_13','dist_from_14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols + dist_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[dist_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_dist'] = df[dist_cols].agg('min', axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols+dist_cols+['min_dist']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
