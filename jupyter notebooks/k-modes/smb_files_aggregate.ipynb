{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been modified to remove sensitive data. It excludes the original dataset, the output of each cell, and some feature engineering based off of domain knowledge. The inputs are still included for the purpose of understanding our machine learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from kmodes.kmodes import KModes\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from kmodes.kprototypes import KPrototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "limit the dataframe to the size we can handle by pulling in 1 in 20 rows. Dr. Keith says this should still be representative of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = []\n",
    "for i in range(800000000):\n",
    "    if i % 100 != 0:\n",
    "        skip.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\hanbrolo\\Documents\\smb_files_3.18_to_3.25.csv\",skiprows=skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert fields to appropriate data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ts = pd.to_datetime(df.ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new data frame that aggregates by session. We want to discover users who at a certain time accessed/downloaded files in an anomalous fashion (not just individual records, but their whole session)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df.groupby(['uid','id.orig_h','id.resp_h'])[['ts']].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.reset_index(level=['id.orig_h', 'id.resp_h'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engineer features including total session file size, total count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['size'] = df.groupby(['uid','id.orig_h','id.resp_h'])['size'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['count'] = df.groupby(['uid','id.orig_h','id.resp_h'])['size'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['size_normalized'] = stats.zscore(df_agg['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['count_normalized'] = stats.zscore(df_agg['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on domain knowledge, we've grouped IPs into different departments or services they represent. We use this engineered feature in our model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The logic for this feature has been removed from the notebook due to its sensitive nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another engineered feature - cagetorical buckets for day of week and time of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.ts = pd.to_datetime(df_agg.ts)\n",
    "df_agg['day_of_week'] = df_agg.ts.dt.weekday_name\n",
    "hours = {\n",
    "    0: \"late_night\",\n",
    "    1: \"late_night\",\n",
    "    2: \"early_morning\",\n",
    "    3: \"early_morning\",\n",
    "    4: \"early_morning\",\n",
    "    5: \"early_morning\",\n",
    "    6: \"morning\",\n",
    "    7: \"morning\",\n",
    "    8: \"morning\",\n",
    "    9: \"morning\",\n",
    "    10: \"afternoon\",\n",
    "    11: \"afternoon\",\n",
    "    12: \"afternoon\",\n",
    "    13: \"afternoon\",\n",
    "    14: \"evening\",\n",
    "    15: \"evening\",\n",
    "    16: \"evening\",\n",
    "    17: \"evening\",\n",
    "    18: \"night\",\n",
    "    19: \"night\",\n",
    "    20: \"night\",\n",
    "    21: \"night\",\n",
    "    22: \"late_night\",\n",
    "    23: \"late_night\"\n",
    "}\n",
    "df_agg['time_of_day_bin'] =  [hours[i] for i in df_agg.ts.dt.hour]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['size'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['size'] = df_agg['size'].fillna(0)\n",
    "df_agg = df_agg.fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['size_normalized','count_normalized','orig_ip_group','resp_ip_group','day_of_week','time_of_day_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train k-prototypes (k-prototypes considers both categorical and numeric features for its distance measure). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kproto = KPrototypes(n_clusters=5, init='Cao', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = kproto.fit_predict(df_agg[cols].values, categorical=[2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kproto.cluster_centroids_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign each record to a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.groupby('cluster')['ts'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate a cluster that looks anomalous (this one shows a very large total download size by session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg[df_agg['cluster']==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the distance from each categorical cluster centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_cols = ['orig_ip_group','resp_ip_group','day_of_week','time_of_day_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissim_distance(a,b):\n",
    "    distance = 0\n",
    "    for ai, bi in zip(a,b):\n",
    "        if ai != bi:\n",
    "            distance += 1\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_dist(row):\n",
    "    cluster_index = row['cluster']\n",
    "    return dissim_distance(row[categ_cols],kproto.cluster_centroids_[1][cluster_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['min_categ_dist'] = df_agg.apply(lambda row: get_min_dist(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.to_pickle(\"smb_files_aggregate_k_prototypes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show records that are anomalous across both numeric and categorical features. Investigate these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg[(df_agg['min_categ_dist'] > 2) & (df_agg['cluster']==2)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
