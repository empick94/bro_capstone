{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been modified to remove sensitive data. It excludes the original dataset, the output of each cell, and some feature engineering based off of domain knowledge. The inputs are still included for the purpose of understanding our machine learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from kmodes.kmodes import KModes\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in dataset - limit it to 1 in 20 rows so it's a manageable size for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = []\n",
    "for i in range(100000000):\n",
    "    if i % 20 != 0:\n",
    "        skip.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\hanbrolo\\Documents\\ntlm_2.25_to_3.4.csv\", skiprows=skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also read in the full dataset to assign clusters to all rows based on the model that we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(r\"C:\\Users\\hanbrolo\\Documents\\ntlm_2.25_to_3.4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on domain knowledge, we've grouped IPs into different departments or services they represent. We use this engineered feature in our model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The logic for this feature has been removed from the notebook due to its sensitive nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another engineered feature - cagetorical buckets for day of week and time of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ts = pd.to_datetime(df.ts)\n",
    "df['day_of_week'] = df.ts.dt.weekday_name\n",
    "hours = {\n",
    "    0: \"late_night\",\n",
    "    1: \"late_night\",\n",
    "    2: \"early_morning\",\n",
    "    3: \"early_morning\",\n",
    "    4: \"early_morning\",\n",
    "    5: \"early_morning\",\n",
    "    6: \"morning\",\n",
    "    7: \"morning\",\n",
    "    8: \"morning\",\n",
    "    9: \"morning\",\n",
    "    10: \"afternoon\",\n",
    "    11: \"afternoon\",\n",
    "    12: \"afternoon\",\n",
    "    13: \"afternoon\",\n",
    "    14: \"evening\",\n",
    "    15: \"evening\",\n",
    "    16: \"evening\",\n",
    "    17: \"evening\",\n",
    "    18: \"night\",\n",
    "    19: \"night\",\n",
    "    20: \"night\",\n",
    "    21: \"night\",\n",
    "    22: \"late_night\",\n",
    "    23: \"late_night\"\n",
    "}\n",
    "df['time_of_day_bin'] =  [hours[i] for i in df.ts.dt.hour]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['domainname','status','id.resp_p','orig_ip_first','orig_ip_middle','resp_ip_first','resp_ip_middle','day_of_week','time_of_day_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id.resp_p'] = df['id.resp_p'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle missing fields as their own category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols] = df[cols].fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with 10 clusters. Thus number provided enough distinct examples of \"normal\" behavior could be like that our anomalies were meaningful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KModes(n_clusters=10, init='Huang', n_init=4, verbose=2)\n",
    "clusters = km.fit_predict(df[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign each record to its nearest cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clusters'] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the cluster centroids to learn more about them and what our most common traffic looks like. \n",
    "These centroids represent the most common values for each of the chosen features. We'll identify the records that are the most dissimilar to these centroids in order to find anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.cluster_centroids_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a distance measure then calculate the distance between each record and its cluster centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissim_distance(a,b):\n",
    "    distance = 0\n",
    "    for ai, bi in zip(a,b):\n",
    "        if ai != bi:\n",
    "            distance += 1\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_dist(row):\n",
    "    cluster_index = row['clusters']\n",
    "    return dissim_distance(row[cols],km.cluster_centroids_[cluster_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_dist'] = df.apply(lambda row: get_min_dist(row),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the records with the greatest distance from their cluster centroid (the anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_anomalies = \n",
    "df[df['min_dist'] > 6]\n",
    "#df_anomalies.to_pickle(\"kmodes_ntlm_anomalies_9_cols_10_clusters\")\n",
    "#df_anomalies.to_csv(\"kmodes_ntlm_anomalies_9_cols_10_clusters.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
